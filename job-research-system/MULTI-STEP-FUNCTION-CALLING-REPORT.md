# Multi-Step Function Calling Implementation Report

**Status:** âœ… **IMPLEMENTED**  
**Location:** `job-research-mcp/src/services/llm-analyzer.ts`  
**Date:** 2025-01-27

## Executive Summary

âœ… **Yes, the codebase has multi-step function calling implemented.**

The system uses OpenAI's tool calling API with a **while loop** that allows the LLM to make multiple sequential function calls until it completes its analysis. This enables the AI to:

1. Call tools to gather information
2. Receive tool results
3. Make additional tool calls based on results
4. Continue iterating until analysis is complete

---

## Implementation Details

### Core Mechanism

**File:** `job-research-mcp/src/services/llm-analyzer.ts`  
**Method:** `callOpenAIWithTools()`  
**Lines:** 498-612

```typescript
// Handle tool calls - execute tools and send results back
let toolCallCount = 0;
const maxToolCalls = 10; // Prevent infinite loops

while (message.tool_calls && toolCallCount < maxToolCalls) {
  toolCallCount++;
  console.log(`ðŸ”§ Processing ${message.tool_calls.length} tool call(s)...`);
  
  // 1. Add assistant message with tool calls
  messages.push({
    role: 'assistant',
    content: message.content || null,
    tool_calls: message.tool_calls,
  });

  // 2. Execute each tool call
  for (const toolCall of message.tool_calls) {
    // ... execute tool ...
    // ... add tool result to messages ...
  }

  // 3. Make another API call with tool results
  response = await fetch('https://api.openai.com/v1/chat/completions', {
    // ... API call with updated messages ...
  });

  // 4. Get next message (may contain more tool_calls)
  apiResponse = await response.json();
  message = apiResponse.choices[0].message;
}
```

### Key Features

1. **Iterative Loop**
   - Continues while `message.tool_calls` exists
   - Maximum 10 iterations to prevent infinite loops
   - Each iteration processes all tool calls in parallel

2. **Tool Execution**
   - Executes tools sequentially within each iteration
   - Adds tool results to message history
   - Handles errors gracefully

3. **Progressive Refinement**
   - LLM can make multiple rounds of tool calls
   - Each round can use results from previous rounds
   - Continues until LLM provides final analysis

---

## Available Tools

The system implements **2 tools** that the LLM can call:

### 1. `extract_skills`
**Purpose:** Deterministically extract skills from text  
**File:** `tool-helpers.ts`  
**Function:** `extractSkills(text: string)`

**Parameters:**
- `text` (string): Text to extract skills from

**Returns:**
```typescript
{
  skills: string[],
  skillCategories: Record<string, string[]>,
  confidence: 'high' | 'medium' | 'low'
}
```

**Usage Example:**
```typescript
// LLM calls: extract_skills("Looking for React, TypeScript, Node.js developer")
// Returns: { skills: ["React", "TypeScript", "Node.js"], ... }
```

### 2. `calculate_similarity`
**Purpose:** Calculate semantic similarity using embeddings  
**File:** `tool-helpers.ts`  
**Function:** `calculateEmbeddingSimilarity(text1, text2, apiKey)`

**Parameters:**
- `text1` (string): First text to compare
- `text2` (string): Second text to compare
- `comparison_type` (string): One of:
  - `role_alignment`
  - `technical_match`
  - `company_fit`
  - `growth_potential`

**Returns:**
```typescript
{
  similarity: number,      // 0-1 cosine similarity
  score: number,           // 0-100 normalized score
  interpretation: string   // "very high" | "high" | "moderate" | "low" | "very low"
}
```

**Usage Example:**
```typescript
// LLM calls: calculate_similarity(job_desc, cv_content, "role_alignment")
// Returns: { similarity: 0.85, score: 85, interpretation: "high" }
```

---

## Multi-Step Flow Example

Here's how a typical multi-step analysis works:

### Step 1: Initial Request
```
LLM receives: Job description + CV content
LLM decides: "I need to extract skills from both texts"
LLM calls: extract_skills(job_requirements)
LLM calls: extract_skills(cv_content)
```

### Step 2: Process Tool Results
```
System executes: extract_skills() for both calls
System adds: Tool results to message history
System makes: Another API call with tool results
```

### Step 3: LLM Continues Analysis
```
LLM receives: Tool results (skill lists)
LLM decides: "Now I need similarity scores"
LLM calls: calculate_similarity(job_desc, cv, "role_alignment")
LLM calls: calculate_similarity(job_desc, cv, "technical_match")
LLM calls: calculate_similarity(job_desc, cv, "company_fit")
```

### Step 4: Final Analysis
```
LLM receives: All similarity scores
LLM decides: "I have enough information"
LLM provides: Final analysis JSON (no more tool_calls)
Loop exits: âœ… Complete
```

---

## Safety Features

### 1. Maximum Iteration Limit
```typescript
const maxToolCalls = 10; // Prevent infinite loops
```
- Prevents infinite loops if LLM keeps requesting tools
- Logs warning if limit is reached

### 2. Error Handling
```typescript
try {
  // Execute tool
} catch (error) {
  // Return error to LLM
  toolResult = { error: error.message };
}
```
- Tool errors are caught and returned to LLM
- LLM can handle errors and continue or retry

### 3. Progress Tracking
```typescript
this.emitProgress('tool_call', `Calling ${toolName}...`);
this.emitProgress('tool_result', `Extracted ${count} skills`);
```
- Real-time progress updates via SSE
- Frontend can display reasoning steps

---

## Code Locations

### Backend Implementation
- **Main Implementation:** `job-research-mcp/src/services/llm-analyzer.ts`
  - Lines 498-612: Multi-step loop
  - Lines 411-616: `callOpenAIWithTools()` method
  - Lines 527-574: Tool execution logic

- **Tool Helpers:** `job-research-mcp/src/services/tool-helpers.ts`
  - `extractSkills()`: Skill extraction tool
  - `calculateEmbeddingSimilarity()`: Similarity calculation tool

### Frontend Integration
- **API Client:** `job-research-ui/src/services/api.ts`
  - Lines 231-471: `analyzeJobWithAI()` function
  - Handles SSE streaming of tool call progress

- **UI Components:** `job-research-ui/src/components/AIJobAnalysisModal.tsx`
  - Displays tool call progress to users
  - Shows reasoning steps in real-time

---

## Configuration

### Model Settings
```typescript
private readonly MODEL = 'gpt-4o-mini'; // Supports tool calling
```

### Tool Definitions
```typescript
const tools = [
  {
    type: 'function',
    function: {
      name: 'extract_skills',
      description: 'Extract skills deterministically from text',
      parameters: { /* ... */ }
    }
  },
  {
    type: 'function',
    function: {
      name: 'calculate_similarity',
      description: 'Calculate semantic similarity using embeddings',
      parameters: { /* ... */ }
    }
  }
];
```

### API Configuration
```typescript
{
  model: this.MODEL,
  messages,
  tools,
  tool_choice: 'auto',  // LLM decides when to use tools
  temperature: 0.7,
  max_tokens: 2000,
}
```

---

## Benefits of Multi-Step Function Calling

### 1. **Deterministic Skill Extraction**
- Before: LLM inferred skills inconsistently
- After: Uses deterministic `extract_skills` tool â†’ consistent results

### 2. **Objective Scoring**
- Before: Subjective LLM scoring
- After: Uses `calculate_similarity` with embeddings â†’ data-driven scores

### 3. **Progressive Refinement**
- LLM can gather information step-by-step
- Can make decisions based on intermediate results
- More accurate final analysis

### 4. **Transparency**
- Users see reasoning steps in real-time
- Tool calls are logged and displayed
- Better debugging and trust

---

## Testing

To verify multi-step function calling:

1. **Enable Logging:**
   ```bash
   # Check backend logs for:
   ðŸ”§ Processing N tool call(s)...
   âœ… Extracted N skills from text
   âœ… Calculated similarity: X% (comparison_type)
   ```

2. **Check Frontend:**
   - Open AI Job Analysis modal
   - Watch for tool call progress updates
   - Verify multiple tool calls appear sequentially

3. **API Test:**
   ```bash
   curl -X POST http://localhost:3001/api/jobs/ai-analyze \
     -H "Content-Type: application/json" \
     -d '{"job_id": 1, "cv_id": 1, "stream": true}'
   ```

---

## Limitations

1. **Maximum Iterations:** Limited to 10 tool call rounds
   - Usually sufficient for job analysis
   - May need adjustment for complex workflows

2. **Sequential Execution:** Tools execute sequentially within each round
   - Could be parallelized for performance
   - Current implementation prioritizes clarity

3. **Error Recovery:** Limited error recovery
   - Tool errors are returned to LLM
   - LLM may not always handle errors optimally

---

## Future Enhancements

Potential improvements:

1. **Parallel Tool Execution**
   - Execute independent tools in parallel
   - Reduce total analysis time

2. **Dynamic Tool Selection**
   - Add/remove tools based on job type
   - Domain-specific tools

3. **Tool Result Caching**
   - Cache embedding calculations
   - Reuse skill extractions

4. **More Tools**
   - Company research tool
   - Salary estimation tool
   - Interview question generator

---

## Conclusion

âœ… **Multi-step function calling is fully implemented and working.**

The system successfully:
- âœ… Implements iterative tool calling loop
- âœ… Supports multiple tool types
- âœ… Handles errors gracefully
- âœ… Provides progress tracking
- âœ… Limits iterations for safety
- âœ… Integrates with frontend for real-time updates

The implementation follows OpenAI's tool calling best practices and provides a robust foundation for AI-powered job analysis.

---

## Related Documentation

- `TOOL-CALLING-IMPLEMENTATION.md` - Original implementation guide
- `DEBUG-REASONING-STEPS.md` - Debugging guide for reasoning steps
- `AI-ANALYSIS-IMPLEMENTATION.md` - Overall AI analysis architecture

